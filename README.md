# You can acces extracted features, part one and part two data sets in the [link]((https://drive.google.com/drive/folders/1age5NBRa_YeCvxfVQPtbhgwbI0bEQt24?usp=sharing))

# Img2Vec Class

The `Img2Vec` class provides a flexible and efficient way to convert images into vector embeddings using various pre-trained deep learning models. These embeddings can be used for tasks like image retrieval, clustering, classification, and similarity computation.

## Features
- Supports multiple pre-trained models, including ResNet, EfficientNet, ViT (Vision Transformer), AlexNet, VGG, and DenseNet.
- Option to extract embeddings from specific layers of the model.
- Easily switch between CPU and GPU for inference.
- Handles single images or batches of images seamlessly.

---

## Class Components

### 1. RESNET_OUTPUT_SIZES and EFFICIENTNET_OUTPUT_SIZES
- These dictionaries map model names to their corresponding output feature dimensions.
- This ensures compatibility with different models that produce embeddings of varying sizes.
- For example:
  - `resnet18` produces embeddings of size 512.
  - `efficientnet_b0` produces embeddings of size 1280.

### 2. `__init__` Method
- Initializes the `Img2Vec` instance.
- **Parameters:**
  - `cuda`: Enables GPU acceleration if set to `True`.
  - `model`: Specifies the pre-trained model for embedding extraction (default is Vision Transformer: `'google/vit-base-patch16-224'`).
  - `gpu`: Specifies the GPU device index (if multiple GPUs are available).
- Loads the model and feature extractor and sets the model to evaluation mode.

### 3. `get_vec` Method
- Converts an image (or a batch of images) into a vector embedding.
- **Steps:**
  1. Preprocesses the image(s) using the feature extractor.
  2. Passes the image through the model to compute embeddings.
  3. Computes the mean of the final layerâ€™s hidden states as the embedding.
- **Output:** A NumPy array (default) or PyTorch tensor.

### 4. `_get_model_and_layer` Method
- Internal utility for selecting and loading pre-trained models and their specific layers.
- Supports multiple architectures such as:
  - **ResNet** (e.g., resnet18, resnet50)
  - **EfficientNet** (e.g., efficientnet_b0 to b7)
  - **ViT** (Vision Transformer)
  - **AlexNet, VGG, DenseNet**
- Dynamically adjusts the embedding size (`layer_output_size`) based on the chosen model and layer.

---

## Usage Example

Below is an example of how to use the `Img2Vec` class:

```python
from PIL import Image

# Initialize Img2Vec with Vision Transformer (ViT) on GPU
img2vec = Img2Vec(cuda=True, model='google/vit-base-patch16-224')

# Load an image
img = Image.open('path_to_image.jpg')

# Get vector embedding (NumPy array)
embedding = img2vec.get_vec(img, tensor=False)
print("Embedding shape:", embedding.shape)

# Batch process multiple images
images = [Image.open(f'image_{i}.jpg') for i in range(10)]
embeddings = img2vec.get_vec(images)
print("Batch embeddings shape:", embeddings.shape)


### Note on Feature Extraction and Submission

In the submission file, we are using pre-stored features, which were generated by applying ViT (Vision Transformer) on each image beforehand. This approach was adopted because the dataset contains a large number of images, and feature extraction for the entire dataset is time-intensive. 

However, for a single test input, the feature extraction process using ViT is fast and can be performed in real-time if required. The extracted feature files are provided alongside the Python notebooks, ensuring reproducibility and allowing the evaluation process to focus solely on the prediction pipeline without the overhead of feature computation.


