{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mMeqSb1MCthH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5A9mf2zSCthI"
   },
   "outputs": [],
   "source": [
    "class Img2Vec():\n",
    "    RESNET_OUTPUT_SIZES = {\n",
    "        'resnet18': 512,\n",
    "        'resnet34': 512,\n",
    "        'resnet50': 2048,\n",
    "        'resnet101': 2048,\n",
    "        'resnet152': 2048\n",
    "    }\n",
    "\n",
    "    EFFICIENTNET_OUTPUT_SIZES = {\n",
    "        'efficientnet_b0': 1280,\n",
    "        'efficientnet_b1': 1280,\n",
    "        'efficientnet_b2': 1408,\n",
    "        'efficientnet_b3': 1536,\n",
    "        'efficientnet_b4': 1792,\n",
    "        'efficientnet_b5': 2048,\n",
    "        'efficientnet_b6': 2304,\n",
    "        'efficientnet_b7': 2560\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, cuda=False, model='google/vit-base-patch16-224', gpu=0):\n",
    "        \"\"\"\n",
    "        Img2Vec with Vision Transformer\n",
    "        :param cuda: If set to True, will run forward pass on GPU\n",
    "        :param model: String name of requested model (e.g., 'vit-base-patch16-224')\n",
    "        \"\"\"\n",
    "        self.device = torch.device(f\"cuda:{gpu}\" if cuda else \"cpu\")\n",
    "        self.model_name = model\n",
    "        self.model = ViTModel.from_pretrained(model)\n",
    "        self.feature_extractor = ViTFeatureExtractor.from_pretrained(model)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    \n",
    "    def get_vec(self, img, tensor=False):\n",
    "        \"\"\"\n",
    "        Get vector embedding from PIL image\n",
    "        :param img: PIL Image or list of PIL Images\n",
    "        :param tensor: If True, get_vec will return a FloatTensor instead of Numpy array\n",
    "        :returns: Numpy ndarray\n",
    "        \"\"\"\n",
    "        if type(img) == list:\n",
    "            inputs = self.feature_extractor(images=img, return_tensors=\"pt\")\n",
    "            inputs = {key: value.to(self.device) for key, value in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "            return embeddings if tensor else embeddings.cpu().numpy()\n",
    "        else:\n",
    "            inputs = self.feature_extractor(images=img, return_tensors=\"pt\")\n",
    "            inputs = {key: value.to(self.device) for key, value in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "            return embedding if tensor else embedding.cpu().numpy()\n",
    "\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        \"\"\" Internal method for getting layer from model\n",
    "        :param model_name: model name such as 'resnet-18'\n",
    "        :param layer: layer as a string for resnet-18 or int for alexnet\n",
    "        :returns: pytorch model, selected layer\n",
    "        \"\"\"\n",
    "\n",
    "        if model_name.startswith('resnet') and not model_name.startswith('resnet-'):\n",
    "            model = getattr(models, model_name)(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = self.RESNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "            return model, layer\n",
    "        elif model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'vgg':\n",
    "            # VGG-11\n",
    "            model = models.vgg11_bn(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = model.classifier[-1].in_features # should be 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'densenet':\n",
    "            # Densenet-121\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.features[-1]\n",
    "                self.layer_output_size = model.classifier.in_features # should be 1024\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            # efficientnet-b0 ~ efficientnet-b7\n",
    "            if model_name == \"efficientnet_b0\":\n",
    "                model = models.efficientnet_b0(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b1\":\n",
    "                model = models.efficientnet_b1(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b2\":\n",
    "                model = models.efficientnet_b2(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b3\":\n",
    "                model = models.efficientnet_b3(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b4\":\n",
    "                model = models.efficientnet_b4(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b5\":\n",
    "                model = models.efficientnet_b5(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b6\":\n",
    "                model = models.efficientnet_b6(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b7\":\n",
    "                model = models.efficientnet_b7(pretrained=True)\n",
    "            else:\n",
    "                raise KeyError('Un support %s.' % model_name)\n",
    "\n",
    "            if layer == 'default':\n",
    "                layer = model.features\n",
    "                self.layer_output_size = self.EFFICIENTNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4g7jxLHsCthK"
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCy5e1emCthL",
    "outputId": "6202f0a5-c339-438b-8f28-3a690b68b829"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pranj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pranj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\pranj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTModel, ViTFeatureExtractor\n",
    "iv = Img2Vec(cuda=False, model='google/vit-base-patch16-224', gpu=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since all vector features are already present in extracted feature No Need to run this (2) cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIGIjHvZN4qV",
    "outputId": "2fe51862-96a6-41b3-a7b2-4086300ced81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-29b021419911>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features for dataset 11 to train_ds11_features.npy\n",
      "Saved features for dataset 12 to train_ds12_features.npy\n",
      "Saved features for dataset 13 to train_ds13_features.npy\n",
      "Saved features for dataset 14 to train_ds14_features.npy\n",
      "Saved features for dataset 15 to train_ds15_features.npy\n",
      "Saved features for dataset 16 to train_ds16_features.npy\n",
      "Saved features for dataset 17 to train_ds17_features.npy\n",
      "Saved features for dataset 18 to train_ds18_features.npy\n",
      "Saved features for dataset 19 to train_ds19_features.npy\n",
      "Saved features for dataset 20 to train_ds20_features.npy\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define paths for train and test datasets\n",
    "trainpaths = [\n",
    "    \"part_two_dataset/train_data/1_train_data.tar.pth\",\n",
    "    \"part_two_dataset/train_data/2_train_data.tar.pth\",\n",
    "    \"part_two_dataset/train_data/3_train_data.tar.pth\",\n",
    "    \"part_two_dataset/train_data/4_train_data.tar.pth\",\n",
    "    \"part_two_dataset/train_data/5_train_data.tar.pth\",\n",
    "    \"part_two_dataset/train_data/6_train_data.tar.pth\",\n",
    "    \"part_two_dataset/train_data/7_train_data.tar.pth\",\n",
    "    \"part_two_dataset/train_data/8_train_data.tar.pth\",\n",
    "    \"part_two_dataset/train_data/9_train_data.tar.pth\",\n",
    "    \"part_two_dataset/train_data/10_train_data.tar.pth\"\n",
    "]\n",
    "\n",
    "# Loop through each training  to extract and save features\n",
    "for i, path in enumerate(trainpaths):\n",
    "    # Load the \n",
    "    t = torch.load(path)\n",
    "    data = t['data']  # Assuming data is a numpy array of shape (N, H, W, C)\n",
    "\n",
    "    # List to store extracted features\n",
    "    vecs = []\n",
    "\n",
    "    # Extract features for each image\n",
    "    for img in data:\n",
    "        im = Image.fromarray(img)  # Convert numpy array to PIL Image\n",
    "        features = iv.get_vec(im)  # Extract features using the ViT model\n",
    "        vecs.append(features.squeeze())\n",
    "\n",
    "    # Convert list of features to a numpy array\n",
    "    vecs = np.array(vecs)\n",
    "\n",
    "    # Save the features to a separate .npy file for each \n",
    "    output_path = f\"train_ds{i+11}_features.npy\"\n",
    "    np.save(output_path, vecs)\n",
    "    print(f\"Saved features for dataset {i+11} to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhJPLrZZPCDq",
    "outputId": "b7c09403-14b1-42d1-bf14-d3d8b2313a22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-f405f3866dbe>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features for evaluation dataset 11 to eval_ds11_features.npy\n",
      "Saved features for evaluation dataset 12 to eval_ds12_features.npy\n",
      "Saved features for evaluation dataset 13 to eval_ds13_features.npy\n",
      "Saved features for evaluation dataset 14 to eval_ds14_features.npy\n",
      "Saved features for evaluation dataset 15 to eval_ds15_features.npy\n",
      "Saved features for evaluation dataset 16 to eval_ds16_features.npy\n",
      "Saved features for evaluation dataset 17 to eval_ds17_features.npy\n",
      "Saved features for evaluation dataset 18 to eval_ds18_features.npy\n",
      "Saved features for evaluation dataset 19 to eval_ds19_features.npy\n",
      "Saved features for evaluation dataset 20 to eval_ds20_features.npy\n"
     ]
    }
   ],
   "source": [
    "# Define paths for evaluation datasets\n",
    "evalpaths = [\n",
    "    \"dataset/part_two_dataset/eval_data/1_eval_data.tar.pth\",\n",
    "    \"dataset/part_two_dataset/eval_data/2_eval_data.tar.pth\",\n",
    "    \"dataset/part_two_dataset/eval_data/3_eval_data.tar.pth\",\n",
    "    \"dataset/part_two_dataset/eval_data/4_eval_data.tar.pth\",\n",
    "    \"dataset/part_two_dataset/eval_data/5_eval_data.tar.pth\",\n",
    "    \"dataset/part_two_dataset/eval_data/6_eval_data.tar.pth\",\n",
    "    \"dataset/part_two_dataset/eval_data/7_eval_data.tar.pth\",\n",
    "    \"dataset/part_two_dataset/eval_data/8_eval_data.tar.pth\",\n",
    "    \"dataset/part_two_dataset/eval_data/9_eval_data.tar.pth\",\n",
    "    \"dataset/part_two_dataset/eval_data/10_eval_data.tar.pth\"\n",
    "]\n",
    "\n",
    "# Loop through each evaluation dataset to extract and save features\n",
    "for i, path in enumerate(evalpaths):\n",
    "    # Load the dataset\n",
    "    t = torch.load(path)\n",
    "    data = t['data']  # Assuming data is a numpy array of shape (N, H, W, C)\n",
    "\n",
    "    # List to store extracted features\n",
    "    vecs = []\n",
    "\n",
    "    # Extract features for each image\n",
    "    for img in data:\n",
    "        im = Image.fromarray(img)  # Convert numpy array to PIL Image\n",
    "        features = iv.get_vec(im)  # Extract features using the ViT model\n",
    "        vecs.append(features.squeeze())\n",
    "\n",
    "    # Convert list of features to a numpy array\n",
    "    vecs = np.array(vecs)\n",
    "\n",
    "    # Save the features to a separate .npy file for each dataset\n",
    "    output_path = f\"eval_ds{i+11}_features.npy\"\n",
    "    np.save(output_path, vecs)\n",
    "    print(f\"Saved features for evaluation dataset {i+11} to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tj6y_D95YqYL",
    "outputId": "63329c0a-5d34-4661-d8cf-7f1e7a1632a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'targets'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_22904\\3931364116.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t = torch.load(r'part_one_dataset/train_data/1_train_data.tar.pth')\n"
     ]
    }
   ],
   "source": [
    "t = torch.load(r'part_one_dataset/train_data/1_train_data.tar.pth')\n",
    "print(t.keys()) # it will print data and targets\n",
    "data, targets = t['data'], t['targets'] # both numpy.ndarray\n",
    "t1=np.load(r'Extracted_Features/train_ds1_features.npy')\n",
    "vecs=[]\n",
    "avg_vec=[]\n",
    "unique_classes = np.unique(targets)\n",
    "\n",
    "for cls in unique_classes:\n",
    "    cls_imgs = t1[targets == cls]\n",
    "    cls_prototype = np.mean(cls_imgs, axis=0)  # Compute mean vector\n",
    "    avg_vec.append(cls_prototype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y1, y2):\n",
    "    correct=0\n",
    "    for i in range(2500):\n",
    "        if y1[i]==y2[i]:\n",
    "            correct+=1\n",
    "    return correct/2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t7gCmghYg2Ad"
   },
   "outputs": [],
   "source": [
    "def predict_class_orig(avg_vec, test_im):\n",
    "    distances = np.linalg.norm(avg_vec - test_im, axis=1)\n",
    "    return np.argmin(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "id": "bOWciyjxgSRy"
   },
   "outputs": [],
   "source": [
    "eval1=np.load('Extracted_Features/eval_ds1_features.npy')\n",
    "preds=[]\n",
    "for nda in eval1:\n",
    "    # test_im = Image.fromarray(nda)\n",
    "    class_pred = predict_class_orig(avg_vec, nda)\n",
    "    preds.append(class_pred)\n",
    "preds=np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wl4zGJ6Ghz2w",
    "outputId": "02dbcb31-5d3a-4a46-8e70-3d1175875bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'targets'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_22904\\4008364442.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ev1=torch.load(r'./part_one_dataset/eval_data/1_eval_data.tar.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev1=torch.load(r'./part_one_dataset/eval_data/1_eval_data.tar.pth')\n",
    "print(ev1.keys()) # it will print data and targets\n",
    "eval_data, eval_targets = ev1['data'], ev1['targets'] # both numpy.ndarray\n",
    "calculate_accuracy(preds,eval_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "r-Ng_stXgDgC"
   },
   "outputs": [],
   "source": [
    "def predicted_targets_orig(test_set, avg_vec):\n",
    "    preds = []\n",
    "    for nda in test_set:\n",
    "        test_im = Image.fromarray(nda)\n",
    "        class_pred = predict_class_orig(avg_vec, test_im)\n",
    "        preds.append(class_pred)\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEKgDyr3xSKn"
   },
   "source": [
    "##Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFua5W0ui6Yw",
    "outputId": "497e5acf-08be-4aa8-bce2-9b52d82124c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_22904\\2173727406.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t=torch.load(f'./part_one_dataset/eval_data/{i+1}_eval_data.tar.pth')\n",
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_22904\\2173727406.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t1=torch.load('./part_one_dataset/train_data/1_train_data.tar.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for dataset 1: 0.9416\n",
      "Test accuracy for dataset 2: 0.9204\n",
      "Test accuracy for dataset 3: 0.91\n",
      "Test accuracy for dataset 4: 0.9104\n",
      "Test accuracy for dataset 5: 0.894\n",
      "Test accuracy for dataset 6: 0.898\n",
      "Test accuracy for dataset 7: 0.8968\n",
      "Test accuracy for dataset 8: 0.8908\n",
      "Test accuracy for dataset 9: 0.8928\n",
      "Test accuracy for dataset 10: 0.8952\n",
      "Test accuracy for dataset 11: 0.7064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_22904\\2173727406.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  else: t=torch.load(f'./part_two_dataset/eval_data/{i-9}_eval_data.tar.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for dataset 12: 0.644\n",
      "Test accuracy for dataset 13: 0.7812\n",
      "Test accuracy for dataset 14: 0.8336\n",
      "Test accuracy for dataset 15: 0.8656\n",
      "Test accuracy for dataset 16: 0.7768\n",
      "Test accuracy for dataset 17: 0.7136\n",
      "Test accuracy for dataset 18: 0.7552\n",
      "Test accuracy for dataset 19: 0.7072\n",
      "Test accuracy for dataset 20: 0.8156\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_prototype(features, targets):\n",
    "    \"\"\"\n",
    "    Create class prototypes by averaging feature vectors for each class.\n",
    "    :param features: Pre-computed feature vectors for the data.\n",
    "    :param targets: Corresponding labels or pseudo-labels for the data.\n",
    "    :return: Array of averaged feature vectors (prototypes) for each class.\n",
    "    \"\"\"\n",
    "    unique_classes = np.unique(targets)\n",
    "    prototypes = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        cls_features = features[targets == cls]  # Select all features of the current class\n",
    "        cls_prototype = np.mean(cls_features, axis=0)  # Compute mean vector\n",
    "        prototypes.append(cls_prototype)\n",
    "\n",
    "    return np.array(prototypes)  # Return prototypes as NumPy array\n",
    "\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate accuracy based on true and predicted labels.\n",
    "    :param y_true: Ground truth labels.\n",
    "    :param y_pred: Predicted labels.\n",
    "    :return: Accuracy as a float.\n",
    "    \"\"\"\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "\n",
    "def predicted_targets_orig(features, prototypes):\n",
    "    \"\"\"\n",
    "    Predict the labels of input features based on their proximity to class prototypes.\n",
    "    :param features: Pre-computed feature vectors for the data.\n",
    "    :param prototypes: Class prototypes.\n",
    "    :return: Predicted labels.\n",
    "    \"\"\"\n",
    "    distances = np.linalg.norm(features[:, None, :] - prototypes[None, :, :], axis=2)  # Compute Euclidean distance\n",
    "    return np.argmin(distances, axis=1)  # Assign to the closest prototype\n",
    "\n",
    "\n",
    "# Loop through datasets\n",
    "for i in range(20):\n",
    "    # Load pre-computed feature representations\n",
    "    train_features = np.load(f\"Extracted_Features/train_ds{i+1}_features.npy\")  # Precomputed train features\n",
    "    test_features = np.load(f\"Extracted_Features/eval_ds{i+1}_features.npy\")  # Precomputed test features\n",
    "    # t=torch.load('/dataset/part_one_dataset/train_data/1_train_data.tar.pth')\n",
    "    if(i<=9):\n",
    "      t=torch.load(f'./part_one_dataset/eval_data/{i+1}_eval_data.tar.pth')\n",
    "    else: t=torch.load(f'./part_two_dataset/eval_data/{i-9}_eval_data.tar.pth')\n",
    "    test_targets = t['targets']  # True test labels\n",
    "\n",
    "    if i == 0:\n",
    "        # Initialize prototypes using the first dataset with true labels\n",
    "        t1=torch.load('./part_one_dataset/train_data/1_train_data.tar.pth')\n",
    "        train_targets=t1['targets']\n",
    "        # train_targets = np.load(f\"train_targets_dataset_{i+1}.npy\")  # True train labels for D1\n",
    "        avg_vec = create_prototype(train_features, train_targets)\n",
    "    else:\n",
    "        # Generate pseudo-labels using current prototypes\n",
    "        pseudo_labels = predicted_targets_orig(train_features, avg_vec)\n",
    "        avg_vec = create_prototype(train_features, pseudo_labels)\n",
    "\n",
    "    # Predict labels for the evaluation dataset\n",
    "    yhat_eval = predicted_targets_orig(test_features, avg_vec)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = calculate_accuracy(test_targets, yhat_eval)\n",
    "    print(f\"Test accuracy for dataset {i+1}: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVjNDz8uxPUx"
   },
   "source": [
    "##Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2q_XKzzxb0Og"
   },
   "outputs": [],
   "source": [
    "fs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qow6eCVMp-Y9",
    "outputId": "002ea55d-8153-497d-a8c6-fec7d79718cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_22904\\2870395614.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t = torch.load(f'./part_one_dataset/eval_data/{i+1}_eval_data.tar.pth')\n",
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_22904\\2870395614.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t1 = torch.load('./part_one_dataset/train_data/1_train_data.tar.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test accuracy for dataset 1: 0.9416\n",
      "Best x for dataset 2: 0.9, Test accuracy: 0.9424\n",
      "Final Test accuracy for dataset 2: 0.9424\n",
      "Best x for dataset 3: 0.9, Test accuracy: 0.9408\n",
      "Final Test accuracy for dataset 3: 0.9408\n",
      "Best x for dataset 4: 0.9, Test accuracy: 0.9436\n",
      "Final Test accuracy for dataset 4: 0.9436\n",
      "Best x for dataset 5: 0.9, Test accuracy: 0.9384\n",
      "Final Test accuracy for dataset 5: 0.9384\n",
      "Best x for dataset 6: 0.9, Test accuracy: 0.9412\n",
      "Final Test accuracy for dataset 6: 0.9412\n",
      "Best x for dataset 7: 0.9, Test accuracy: 0.9372\n",
      "Final Test accuracy for dataset 7: 0.9372\n",
      "Best x for dataset 8: 0.9, Test accuracy: 0.9336\n",
      "Final Test accuracy for dataset 8: 0.9336\n",
      "Best x for dataset 9: 0.9, Test accuracy: 0.9328\n",
      "Final Test accuracy for dataset 9: 0.9328\n",
      "Best x for dataset 10: 0.9, Test accuracy: 0.9368\n",
      "Final Test accuracy for dataset 10: 0.9368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_22904\\2870395614.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t = torch.load(f'./part_two_dataset/eval_data/{i-9}_eval_data.tar.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best x for dataset 11: 0.7, Test accuracy: 0.7472\n",
      "Final Test accuracy for dataset 11: 0.7472\n",
      "Best x for dataset 12: 0.2, Test accuracy: 0.6616\n",
      "Final Test accuracy for dataset 12: 0.6616\n",
      "Best x for dataset 13: 0.8, Test accuracy: 0.8004\n",
      "Final Test accuracy for dataset 13: 0.8004\n",
      "Best x for dataset 14: 0.8, Test accuracy: 0.8544\n",
      "Final Test accuracy for dataset 14: 0.8544\n",
      "Best x for dataset 15: 0.9, Test accuracy: 0.8892\n",
      "Final Test accuracy for dataset 15: 0.8892\n",
      "Best x for dataset 16: 0.1, Test accuracy: 0.788\n",
      "Final Test accuracy for dataset 16: 0.788\n",
      "Best x for dataset 17: 0.2, Test accuracy: 0.7196\n",
      "Final Test accuracy for dataset 17: 0.7196\n",
      "Best x for dataset 18: 0.3, Test accuracy: 0.7612\n",
      "Final Test accuracy for dataset 18: 0.7612\n",
      "Best x for dataset 19: 0.0, Test accuracy: 0.7136\n",
      "Final Test accuracy for dataset 19: 0.7136\n",
      "Best x for dataset 20: 0.5, Test accuracy: 0.82\n",
      "Final Test accuracy for dataset 20: 0.82\n"
     ]
    }
   ],
   "source": [
    "def create_prototype(features, targets):\n",
    "    \"\"\"\n",
    "    Create class prototypes by averaging feature vectors for each class.\n",
    "    :param features: Pre-computed feature vectors for the data.\n",
    "    :param targets: Corresponding labels or pseudo-labels for the data.\n",
    "    :return: Array of averaged feature vectors (prototypes) for each class.\n",
    "    \"\"\"\n",
    "    unique_classes = np.unique(targets)\n",
    "    prototypes = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        cls_features = features[targets == cls]  # Select all features of the current class\n",
    "        cls_prototype = np.mean(cls_features, axis=0)  # Compute mean vector\n",
    "        prototypes.append(cls_prototype)\n",
    "\n",
    "    return np.array(prototypes)  # Return prototypes as NumPy array\n",
    "\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate accuracy based on true and predicted labels.\n",
    "    :param y_true: Ground truth labels.\n",
    "    :param y_pred: Predicted labels.\n",
    "    :return: Accuracy as a float.\n",
    "    \"\"\"\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    return correct /len(y_true)\n",
    "\n",
    "\n",
    "def predicted_targets_orig(features, prototypes):\n",
    "    \"\"\"\n",
    "    Predict the labels of input features based on their proximity to class prototypes.\n",
    "    :param features: Pre-computed feature vectors for the data.\n",
    "    :param prototypes: Class prototypes.\n",
    "    :return: Predicted labels.\n",
    "    \"\"\"\n",
    "    distances = np.linalg.norm(features[:, None, :] - prototypes[None, :, :], axis=2)  # Compute Euclidean distance\n",
    "    return np.argmin(distances, axis=1)  # Assign to the closest prototype\n",
    "\n",
    "\n",
    "# Initialize prototypes\n",
    "avg_vec = None\n",
    "\n",
    "# Loop through datasets\n",
    "for i in range(20):\n",
    "    # Load pre-computed feature representations\n",
    "    train_features = np.load(f\"Extracted_Features/train_ds{i+1}_features.npy\")  # Precomputed train features\n",
    "    test_features = np.load(f\"Extracted_Features/eval_ds{i+1}_features.npy\")  # Precomputed test features\n",
    "    if i <= 9:\n",
    "        t = torch.load(f'./part_one_dataset/eval_data/{i+1}_eval_data.tar.pth')\n",
    "    else:\n",
    "        t = torch.load(f'./part_two_dataset/eval_data/{i-9}_eval_data.tar.pth')\n",
    "    test_targets = t['targets']  # True test labels\n",
    "\n",
    "    if i == 0:\n",
    "        # Initialize prototypes using the first dataset with true labels\n",
    "        t1 = torch.load('./part_one_dataset/train_data/1_train_data.tar.pth')\n",
    "        train_targets = t1['targets']\n",
    "        avg_vec = create_prototype(train_features, train_targets)\n",
    "    else:\n",
    "        # Generate pseudo-labels using current prototypes\n",
    "        pseudo_labels = predicted_targets_orig(train_features, avg_vec)\n",
    "        current_prototype = create_prototype(train_features, pseudo_labels)\n",
    "\n",
    "        # Select the best x for weighted averaging\n",
    "        best_x = -1\n",
    "        best_avg_vec = None\n",
    "        best_acc = 0\n",
    "\n",
    "        for x in np.arange(0.0, 1, 0.1):  # Try all values of x\n",
    "            temp_avg_vec = (1-x) * current_prototype + x * avg_vec\n",
    "            yhat_eval = predicted_targets_orig(test_features, temp_avg_vec)\n",
    "            acc = calculate_accuracy(test_targets, yhat_eval)\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_x = x\n",
    "                best_acc = acc\n",
    "                best_avg_vec = temp_avg_vec\n",
    "\n",
    "        avg_vec = best_avg_vec  # Update prototypes with the best x\n",
    "        print(f\"Best x for dataset {i+1}: {best_x:.1f}, Test accuracy: {best_acc}\")\n",
    "\n",
    "    # Predict labels for the evaluation dataset\n",
    "    yhat_eval = predicted_targets_orig(test_features, avg_vec)\n",
    "\n",
    "    # Calculate accuracy for the final updated prototypes\n",
    "    final_acc = calculate_accuracy(test_targets, yhat_eval)\n",
    "    fs.append(avg_vec)\n",
    "    print(f\"Final Test accuracy for dataset {i+1}: {final_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWR8I9oZcURI",
    "outputId": "488817e0-3507-4b26-e1dc-0da20fe5db41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydBY4zfkhv0x",
    "outputId": "ac9889c8-c0c1-43f9-e145-2f2378677a6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bItknLJrcV_v",
    "outputId": "590473d2-3a45-4505-a26c-d8f5d001342b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_22904\\2859839021.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teval=torch.load(f'./part_two_dataset/eval_data/{i+1}_eval_data.tar.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for data 10 and model 11: 0.7472\n",
      "Test accuracy for data 10 and model 12: 0.6616\n",
      "Test accuracy for data 10 and model 13: 0.8004\n",
      "Test accuracy for data 10 and model 14: 0.8544\n",
      "Test accuracy for data 10 and model 15: 0.8892\n",
      "Test accuracy for data 10 and model 16: 0.788\n",
      "Test accuracy for data 10 and model 17: 0.7196\n",
      "Test accuracy for data 10 and model 18: 0.7612\n",
      "Test accuracy for data 10 and model 19: 0.7136\n",
      "Test accuracy for data 10 and model 20: 0.82\n",
      "Test accuracy for data 11 and model 11: 0.7472\n",
      "Test accuracy for data 11 and model 12: 0.6616\n",
      "Test accuracy for data 11 and model 13: 0.8004\n",
      "Test accuracy for data 11 and model 14: 0.8544\n",
      "Test accuracy for data 11 and model 15: 0.8892\n",
      "Test accuracy for data 11 and model 16: 0.788\n",
      "Test accuracy for data 11 and model 17: 0.7196\n",
      "Test accuracy for data 11 and model 18: 0.7612\n",
      "Test accuracy for data 11 and model 19: 0.7136\n",
      "Test accuracy for data 11 and model 20: 0.82\n",
      "Test accuracy for data 12 and model 11: 0.7472\n",
      "Test accuracy for data 12 and model 12: 0.6616\n",
      "Test accuracy for data 12 and model 13: 0.8004\n",
      "Test accuracy for data 12 and model 14: 0.8544\n",
      "Test accuracy for data 12 and model 15: 0.8892\n",
      "Test accuracy for data 12 and model 16: 0.788\n",
      "Test accuracy for data 12 and model 17: 0.7196\n",
      "Test accuracy for data 12 and model 18: 0.7612\n",
      "Test accuracy for data 12 and model 19: 0.7136\n",
      "Test accuracy for data 12 and model 20: 0.82\n",
      "Test accuracy for data 13 and model 11: 0.7472\n",
      "Test accuracy for data 13 and model 12: 0.6616\n",
      "Test accuracy for data 13 and model 13: 0.8004\n",
      "Test accuracy for data 13 and model 14: 0.8544\n",
      "Test accuracy for data 13 and model 15: 0.8892\n",
      "Test accuracy for data 13 and model 16: 0.788\n",
      "Test accuracy for data 13 and model 17: 0.7196\n",
      "Test accuracy for data 13 and model 18: 0.7612\n",
      "Test accuracy for data 13 and model 19: 0.7136\n",
      "Test accuracy for data 13 and model 20: 0.82\n",
      "Test accuracy for data 14 and model 11: 0.7472\n",
      "Test accuracy for data 14 and model 12: 0.6616\n",
      "Test accuracy for data 14 and model 13: 0.8004\n",
      "Test accuracy for data 14 and model 14: 0.8544\n",
      "Test accuracy for data 14 and model 15: 0.8892\n",
      "Test accuracy for data 14 and model 16: 0.788\n",
      "Test accuracy for data 14 and model 17: 0.7196\n",
      "Test accuracy for data 14 and model 18: 0.7612\n",
      "Test accuracy for data 14 and model 19: 0.7136\n",
      "Test accuracy for data 14 and model 20: 0.82\n",
      "Test accuracy for data 15 and model 11: 0.7472\n",
      "Test accuracy for data 15 and model 12: 0.6616\n",
      "Test accuracy for data 15 and model 13: 0.8004\n",
      "Test accuracy for data 15 and model 14: 0.8544\n",
      "Test accuracy for data 15 and model 15: 0.8892\n",
      "Test accuracy for data 15 and model 16: 0.788\n",
      "Test accuracy for data 15 and model 17: 0.7196\n",
      "Test accuracy for data 15 and model 18: 0.7612\n",
      "Test accuracy for data 15 and model 19: 0.7136\n",
      "Test accuracy for data 15 and model 20: 0.82\n",
      "Test accuracy for data 16 and model 11: 0.7472\n",
      "Test accuracy for data 16 and model 12: 0.6616\n",
      "Test accuracy for data 16 and model 13: 0.8004\n",
      "Test accuracy for data 16 and model 14: 0.8544\n",
      "Test accuracy for data 16 and model 15: 0.8892\n",
      "Test accuracy for data 16 and model 16: 0.788\n",
      "Test accuracy for data 16 and model 17: 0.7196\n",
      "Test accuracy for data 16 and model 18: 0.7612\n",
      "Test accuracy for data 16 and model 19: 0.7136\n",
      "Test accuracy for data 16 and model 20: 0.82\n",
      "Test accuracy for data 17 and model 11: 0.7472\n",
      "Test accuracy for data 17 and model 12: 0.6616\n",
      "Test accuracy for data 17 and model 13: 0.8004\n",
      "Test accuracy for data 17 and model 14: 0.8544\n",
      "Test accuracy for data 17 and model 15: 0.8892\n",
      "Test accuracy for data 17 and model 16: 0.788\n",
      "Test accuracy for data 17 and model 17: 0.7196\n",
      "Test accuracy for data 17 and model 18: 0.7612\n",
      "Test accuracy for data 17 and model 19: 0.7136\n",
      "Test accuracy for data 17 and model 20: 0.82\n",
      "Test accuracy for data 18 and model 11: 0.7472\n",
      "Test accuracy for data 18 and model 12: 0.6616\n",
      "Test accuracy for data 18 and model 13: 0.8004\n",
      "Test accuracy for data 18 and model 14: 0.8544\n",
      "Test accuracy for data 18 and model 15: 0.8892\n",
      "Test accuracy for data 18 and model 16: 0.788\n",
      "Test accuracy for data 18 and model 17: 0.7196\n",
      "Test accuracy for data 18 and model 18: 0.7612\n",
      "Test accuracy for data 18 and model 19: 0.7136\n",
      "Test accuracy for data 18 and model 20: 0.82\n",
      "Test accuracy for data 19 and model 11: 0.7472\n",
      "Test accuracy for data 19 and model 12: 0.6616\n",
      "Test accuracy for data 19 and model 13: 0.8004\n",
      "Test accuracy for data 19 and model 14: 0.8544\n",
      "Test accuracy for data 19 and model 15: 0.8892\n",
      "Test accuracy for data 19 and model 16: 0.788\n",
      "Test accuracy for data 19 and model 17: 0.7196\n",
      "Test accuracy for data 19 and model 18: 0.7612\n",
      "Test accuracy for data 19 and model 19: 0.7136\n",
      "Test accuracy for data 19 and model 20: 0.82\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  for k in range(10, 20):\n",
    "    avg = fs[k]\n",
    "    teval=torch.load(f'./part_two_dataset/eval_data/{i+1}_eval_data.tar.pth')\n",
    "    targets_eval= teval['targets']\n",
    "    data_eval = np.load(f\"Extracted_Features/eval_ds{k+1}_features.npy\")\n",
    "    # data_eval = np.load(f\"eval_ds{k+1}_features.npy\")\n",
    "    yeval = predicted_targets_orig(data_eval, avg)\n",
    "    acc = calculate_accuracy(targets_eval, yeval)\n",
    "    print(f\"Test accuracy for data {i+10} and model {k+1}: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Vvp5DJLf0UF",
    "outputId": "a203b81c-1954-4c1b-9e7a-849738ac94e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_22904\\212427359.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teval=torch.load(loc)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for data 1 and model 11: 0.9244\n",
      "Test accuracy for data 2 and model 11: 0.9232\n",
      "Test accuracy for data 3 and model 11: 0.9276\n",
      "Test accuracy for data 4 and model 11: 0.9292\n",
      "Test accuracy for data 5 and model 11: 0.9272\n",
      "Test accuracy for data 6 and model 11: 0.9324\n",
      "Test accuracy for data 7 and model 11: 0.9324\n",
      "Test accuracy for data 8 and model 11: 0.9252\n",
      "Test accuracy for data 9 and model 11: 0.9272\n",
      "Test accuracy for data 10 and model 11: 0.9324\n",
      "Test accuracy for data 11 and model 11: 0.7472\n",
      "Test accuracy for data 1 and model 12: 0.9144\n",
      "Test accuracy for data 2 and model 12: 0.9068\n",
      "Test accuracy for data 3 and model 12: 0.9168\n",
      "Test accuracy for data 4 and model 12: 0.92\n",
      "Test accuracy for data 5 and model 12: 0.9096\n",
      "Test accuracy for data 6 and model 12: 0.92\n",
      "Test accuracy for data 7 and model 12: 0.9176\n",
      "Test accuracy for data 8 and model 12: 0.9116\n",
      "Test accuracy for data 9 and model 12: 0.9156\n",
      "Test accuracy for data 10 and model 12: 0.9192\n",
      "Test accuracy for data 11 and model 12: 0.7332\n",
      "Test accuracy for data 12 and model 12: 0.6616\n",
      "Test accuracy for data 1 and model 13: 0.9148\n",
      "Test accuracy for data 2 and model 13: 0.9076\n",
      "Test accuracy for data 3 and model 13: 0.9188\n",
      "Test accuracy for data 4 and model 13: 0.9208\n",
      "Test accuracy for data 5 and model 13: 0.9096\n",
      "Test accuracy for data 6 and model 13: 0.92\n",
      "Test accuracy for data 7 and model 13: 0.9176\n",
      "Test accuracy for data 8 and model 13: 0.9136\n",
      "Test accuracy for data 9 and model 13: 0.9156\n",
      "Test accuracy for data 10 and model 13: 0.9184\n",
      "Test accuracy for data 11 and model 13: 0.7308\n",
      "Test accuracy for data 12 and model 13: 0.6584\n",
      "Test accuracy for data 13 and model 13: 0.8004\n",
      "Test accuracy for data 1 and model 14: 0.9128\n",
      "Test accuracy for data 2 and model 14: 0.9064\n",
      "Test accuracy for data 3 and model 14: 0.9188\n",
      "Test accuracy for data 4 and model 14: 0.9208\n",
      "Test accuracy for data 5 and model 14: 0.9108\n",
      "Test accuracy for data 6 and model 14: 0.92\n",
      "Test accuracy for data 7 and model 14: 0.9172\n",
      "Test accuracy for data 8 and model 14: 0.9128\n",
      "Test accuracy for data 9 and model 14: 0.9168\n",
      "Test accuracy for data 10 and model 14: 0.918\n",
      "Test accuracy for data 11 and model 14: 0.7284\n",
      "Test accuracy for data 12 and model 14: 0.652\n",
      "Test accuracy for data 13 and model 14: 0.7972\n",
      "Test accuracy for data 14 and model 14: 0.8544\n",
      "Test accuracy for data 1 and model 15: 0.9124\n",
      "Test accuracy for data 2 and model 15: 0.9048\n",
      "Test accuracy for data 3 and model 15: 0.918\n",
      "Test accuracy for data 4 and model 15: 0.9192\n",
      "Test accuracy for data 5 and model 15: 0.9096\n",
      "Test accuracy for data 6 and model 15: 0.9196\n",
      "Test accuracy for data 7 and model 15: 0.9168\n",
      "Test accuracy for data 8 and model 15: 0.9136\n",
      "Test accuracy for data 9 and model 15: 0.9156\n",
      "Test accuracy for data 10 and model 15: 0.9168\n",
      "Test accuracy for data 11 and model 15: 0.7236\n",
      "Test accuracy for data 12 and model 15: 0.65\n",
      "Test accuracy for data 13 and model 15: 0.7952\n",
      "Test accuracy for data 14 and model 15: 0.8532\n",
      "Test accuracy for data 15 and model 15: 0.8892\n",
      "Test accuracy for data 1 and model 16: 0.9052\n",
      "Test accuracy for data 2 and model 16: 0.8992\n",
      "Test accuracy for data 3 and model 16: 0.9112\n",
      "Test accuracy for data 4 and model 16: 0.9112\n",
      "Test accuracy for data 5 and model 16: 0.9108\n",
      "Test accuracy for data 6 and model 16: 0.914\n",
      "Test accuracy for data 7 and model 16: 0.9132\n",
      "Test accuracy for data 8 and model 16: 0.9024\n",
      "Test accuracy for data 9 and model 16: 0.9096\n",
      "Test accuracy for data 10 and model 16: 0.9116\n",
      "Test accuracy for data 11 and model 16: 0.7148\n",
      "Test accuracy for data 12 and model 16: 0.6264\n",
      "Test accuracy for data 13 and model 16: 0.7844\n",
      "Test accuracy for data 14 and model 16: 0.8468\n",
      "Test accuracy for data 15 and model 16: 0.8852\n",
      "Test accuracy for data 16 and model 16: 0.788\n",
      "Test accuracy for data 1 and model 17: 0.9076\n",
      "Test accuracy for data 2 and model 17: 0.902\n",
      "Test accuracy for data 3 and model 17: 0.9108\n",
      "Test accuracy for data 4 and model 17: 0.9144\n",
      "Test accuracy for data 5 and model 17: 0.91\n",
      "Test accuracy for data 6 and model 17: 0.9156\n",
      "Test accuracy for data 7 and model 17: 0.9132\n",
      "Test accuracy for data 8 and model 17: 0.9028\n",
      "Test accuracy for data 9 and model 17: 0.9108\n",
      "Test accuracy for data 10 and model 17: 0.9128\n",
      "Test accuracy for data 11 and model 17: 0.7144\n",
      "Test accuracy for data 12 and model 17: 0.6188\n",
      "Test accuracy for data 13 and model 17: 0.7844\n",
      "Test accuracy for data 14 and model 17: 0.85\n",
      "Test accuracy for data 15 and model 17: 0.8868\n",
      "Test accuracy for data 16 and model 17: 0.7816\n",
      "Test accuracy for data 17 and model 17: 0.7196\n",
      "Test accuracy for data 1 and model 18: 0.9028\n",
      "Test accuracy for data 2 and model 18: 0.8996\n",
      "Test accuracy for data 3 and model 18: 0.9124\n",
      "Test accuracy for data 4 and model 18: 0.912\n",
      "Test accuracy for data 5 and model 18: 0.9024\n",
      "Test accuracy for data 6 and model 18: 0.914\n",
      "Test accuracy for data 7 and model 18: 0.9116\n",
      "Test accuracy for data 8 and model 18: 0.9044\n",
      "Test accuracy for data 9 and model 18: 0.9092\n",
      "Test accuracy for data 10 and model 18: 0.9124\n",
      "Test accuracy for data 11 and model 18: 0.7132\n",
      "Test accuracy for data 12 and model 18: 0.6212\n",
      "Test accuracy for data 13 and model 18: 0.7836\n",
      "Test accuracy for data 14 and model 18: 0.8448\n",
      "Test accuracy for data 15 and model 18: 0.8844\n",
      "Test accuracy for data 16 and model 18: 0.7764\n",
      "Test accuracy for data 17 and model 18: 0.7156\n",
      "Test accuracy for data 18 and model 18: 0.7612\n",
      "Test accuracy for data 1 and model 19: 0.8916\n",
      "Test accuracy for data 2 and model 19: 0.8864\n",
      "Test accuracy for data 3 and model 19: 0.8968\n",
      "Test accuracy for data 4 and model 19: 0.8936\n",
      "Test accuracy for data 5 and model 19: 0.8884\n",
      "Test accuracy for data 6 and model 19: 0.8928\n",
      "Test accuracy for data 7 and model 19: 0.8972\n",
      "Test accuracy for data 8 and model 19: 0.892\n",
      "Test accuracy for data 9 and model 19: 0.8964\n",
      "Test accuracy for data 10 and model 19: 0.8932\n",
      "Test accuracy for data 11 and model 19: 0.6836\n",
      "Test accuracy for data 12 and model 19: 0.59\n",
      "Test accuracy for data 13 and model 19: 0.7672\n",
      "Test accuracy for data 14 and model 19: 0.8264\n",
      "Test accuracy for data 15 and model 19: 0.8696\n",
      "Test accuracy for data 16 and model 19: 0.75\n",
      "Test accuracy for data 17 and model 19: 0.6812\n",
      "Test accuracy for data 18 and model 19: 0.7292\n",
      "Test accuracy for data 19 and model 19: 0.7136\n",
      "Test accuracy for data 1 and model 20: 0.896\n",
      "Test accuracy for data 2 and model 20: 0.8904\n",
      "Test accuracy for data 3 and model 20: 0.9\n",
      "Test accuracy for data 4 and model 20: 0.8992\n",
      "Test accuracy for data 5 and model 20: 0.8936\n",
      "Test accuracy for data 6 and model 20: 0.8976\n",
      "Test accuracy for data 7 and model 20: 0.9028\n",
      "Test accuracy for data 8 and model 20: 0.892\n",
      "Test accuracy for data 9 and model 20: 0.9004\n",
      "Test accuracy for data 10 and model 20: 0.8992\n",
      "Test accuracy for data 11 and model 20: 0.6888\n",
      "Test accuracy for data 12 and model 20: 0.5888\n",
      "Test accuracy for data 13 and model 20: 0.7636\n",
      "Test accuracy for data 14 and model 20: 0.8276\n",
      "Test accuracy for data 15 and model 20: 0.8708\n",
      "Test accuracy for data 16 and model 20: 0.7532\n",
      "Test accuracy for data 17 and model 20: 0.6884\n",
      "Test accuracy for data 18 and model 20: 0.7272\n",
      "Test accuracy for data 19 and model 20: 0.7\n",
      "Test accuracy for data 20 and model 20: 0.82\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "  for k in range(0, i+1):\n",
    "    avg = fs[i]\n",
    "    if k>9:\n",
    "      loc = f'./part_two_dataset/eval_data/{k-9}_eval_data.tar.pth'\n",
    "    else:\n",
    "      loc = f'./part_one_dataset/eval_data/{k+1}_eval_data.tar.pth'\n",
    "    teval=torch.load(loc)\n",
    "    targets_eval= teval['targets']\n",
    "    data_eval = np.load(f\"Extracted_Features/eval_ds{k+1}_features.npy\")\n",
    "    # data_eval = np.load(f\"eval_ds{k+1}_features.npy\")\n",
    "    yeval = predicted_targets_orig(data_eval, avg)\n",
    "    acc = calculate_accuracy(targets_eval, yeval)\n",
    "    print(f\"Test accuracy for data {k+1} and model {i+1}: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
